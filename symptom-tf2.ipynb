{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59c89e-1f35-4411-b401-bd3e4759081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a3c8a-be22-467f-85a7-58fd0b9b61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "vec_dim = 100\n",
    "state_dim = 50\n",
    "sent_len = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891bc462-8192-4c98-acd6-ccde94af59b3",
   "metadata": {},
   "source": [
    "# Load word embedded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f0642-964d-4195-ae4a-b81ba025650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vec():\n",
    "    dict_vec = {}\n",
    "    with open('tokens.vec', 'r', encoding='utf-8') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            line = line.split(' ')\n",
    "            token = line[0]\n",
    "            vec = line[1:-1]\n",
    "            dict_vec[token] = [float(i) for i in vec]\n",
    "    return dict_vec\n",
    "\n",
    "def get_vec(k):\n",
    "    ak = dict_vec.keys()\n",
    "    if k in ak:\n",
    "        return dict_vec[k]\n",
    "    else:\n",
    "        return [0.0]*vec_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35387e5-8ac3-4dc1-b0be-a3f2679cbc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_vec = load_vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a50df3-1ff0-4f79-8852-a26d433f7517",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078a6c6-10b6-4c0a-8072-5bfe6272ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('docs.txt', 'r', encoding='utf-8') as f:\n",
    "    docs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86201fec-8193-46f7-8f9f-ecd323c34bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sents.txt', 'r', encoding='utf-8') as f:\n",
    "    sents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949db07c-9e1a-488b-b7bf-a59bf0a11f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2 = docs[:550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52eed36-80eb-4c79-a2bb-2bb6d35c0ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents2 = []\n",
    "for s in sents:\n",
    "    if s['labels'].count(1) > 0:\n",
    "        sents2.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96011b6-97b1-403d-a77e-9ed6e66f72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sents(doc):\n",
    "    sents = []\n",
    "    tokens = []\n",
    "    labels = []\n",
    "\n",
    "    for t, l in list(zip(doc['text'], doc['labels'])):\n",
    "        if t in ['，', '。', '？', '！']:\n",
    "\n",
    "            sents.append({\n",
    "                'tokens': tokens,\n",
    "                'labels': labels \n",
    "            })\n",
    "\n",
    "            tokens = []\n",
    "            labels = []\n",
    "        else:\n",
    "            tokens.append(t)\n",
    "            labels.append(l)\n",
    "            \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f4889-405b-45dc-b49b-083710c9412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents3 = []\n",
    "for d in docs2:\n",
    "    sents3 += get_sents(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdcd65b-49f1-42d4-aa97-29c6a4cec98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sents, sent_len, vec_dim):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for s in sents:\n",
    "        tokens = s['tokens']\n",
    "        labels = s['labels']\n",
    "\n",
    "        sent = []\n",
    "        lb = []\n",
    "        for t in range(sent_len):\n",
    "            if t <= len(tokens) - 1:\n",
    "                sent.append(get_vec(tokens[t]))\n",
    "                lb.append(float(labels[t]))\n",
    "            else:\n",
    "                sent.append([0.0]*vec_dim)\n",
    "                lb.append(0.0)\n",
    "        x.append(sent)\n",
    "        y.append(lb)\n",
    "\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f287a6-830a-4086-a05b-ebb8e098c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_data(sents2, sent_len, vec_dim)\n",
    "x_train = x\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8af184-97ce-4e14-9db4-ffaa262cfa44",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b3494-9f7b-4959-965e-59d269135f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(sent_len, vec_dim)))\n",
    "model.add(tf.keras.layers.LSTM(state_dim, return_sequences=True))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.add(tf.keras.layers.Lambda(lambda x: tf.squeeze(x)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a3b89-c7bd-4b0c-ac82-965914379f83",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28733905-95ae-4d97-80a0-7ca7cfbb38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ddd3dd-4c55-4e47-aec4-dd9b436f1ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f4abeb-ee4a-478d-b59e-35f7a61e86c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e662b35-495e-4c0f-8726-6062a49aedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda label, outputs: tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(outputs, label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f4c6a-7c90-4723-9945-9f6a5e87565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95, epsilon=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19a42c-1568-420f-aa80-426f2e8bb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer, metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4535984-e0c4-44c4-9ef4-b02917f111d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=50, validation_split=0.1, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c2e0a1-f0b1-4b55-ac1f-621b41242b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae51e1-aa84-4efe-a685-563a8cf3f254",
   "metadata": {},
   "source": [
    "# Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5715619-85a4-40d5-adda-f854b3a20a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sent_html(text, labels):\n",
    "    spans = []\n",
    "    for i in range(min(len(text), len(labels))):\n",
    "        if labels[i] == 1:\n",
    "            spans.append('<span style=\"color:red;\">'+text[i]+'</span>')\n",
    "        else:\n",
    "            spans.append('<span>'+text[i]+'</span>')\n",
    "    \n",
    "    return ''.join(spans)\n",
    "\n",
    "def print_sent(text, labels):\n",
    "    display(HTML(build_sent_html(text, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df363f9-5cf5-4af5-a69b-629a0f9310af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_compare_sent(s):\n",
    "    tokens = s['tokens']\n",
    "    labels = s['labels']\n",
    "    print_sent(tokens, labels)\n",
    "    \n",
    "    px, py = parse_sent(s, sent_len, vec_dim, batch_size)\n",
    "    pp = model(px).numpy()[0]\n",
    "\n",
    "    pp[pp>=.5] = 1\n",
    "    pp[pp<.5] = 0\n",
    "\n",
    "    tokens = s['tokens']\n",
    "    print_sent(tokens, pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f3b11-051d-412c-8c6b-94dcc81bf5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sent(s, sent_len, vec_dim, batch_size):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    tokens = s['tokens']\n",
    "    labels = s['labels']\n",
    "\n",
    "    sent = []\n",
    "    lb = []\n",
    "    for t in range(sent_len):\n",
    "        if t <= len(tokens) - 1:\n",
    "            sent.append(get_vec(tokens[t]))\n",
    "            lb.append(labels[t])\n",
    "        else:\n",
    "            sent.append([0.0]*vec_dim)\n",
    "            lb.append(0)\n",
    "    x.append(sent)\n",
    "    y.append(lb)\n",
    "    \n",
    "    return np.array(x*batch_size), np.array(y*batch_size)\n",
    "\n",
    "def predict_label(s):\n",
    "    px, py = parse_sent(s, sent_len, vec_dim, batch_size)\n",
    "    pp = model(px).numpy()[0]\n",
    "\n",
    "    pp[pp>=.5] = 1\n",
    "    pp[pp<.5] = 0\n",
    "    \n",
    "    return list(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfa6ea-fdff-49d7-8191-9f1b5ccd6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_doc(sents):\n",
    "    htmls = ''\n",
    "    for s in sents:\n",
    "        htmls += build_sent_html(s['tokens'], s['labels']) + '，'\n",
    "    display(HTML(''.join(htmls)))\n",
    "    \n",
    "    print('\\n')\n",
    "    htmls = ''\n",
    "    for s in sents:\n",
    "        htmls += build_sent_html(s['tokens'], predict_label(s)) + '，'\n",
    "    display(HTML(''.join(htmls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303c630-530c-40cd-b21e-9f1f19d28f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = random.choice(sents2)\n",
    "print_compare_sent(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd208c-a779-402f-8f3f-03f6e727c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = random.choice(docs2)\n",
    "sents3 = get_sents(doc)\n",
    "compare_doc(sents3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c9385-0a35-49e6-bd83-06fabb1bdf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
